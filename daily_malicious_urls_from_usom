import datetime
import requests
import xmltodict, json
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

def write_all_urls_to_json_file(malicious_urls):
    ''' create json file and put in all usom urls '''
    with open('usom_list.json','w') as usom_json_w:
        json.dump(malicious_urls, usom_json_w)

def write_daily_urls_to_txt_file(malicious_urls):
    ''' create txt file and put in urls which only contains current date '''
    counter_url = 0
    while (str(datetime.datetime.now()).split(' '))[0] == ((malicious_urls["usom-data"]["url-list"]["url-info"][counter_url]["date"]).split(' '))[0]:
        with open('usom_list-%s.txt'%(str(datetime.datetime.now()).split(' ')[0]), "a") as text_file:
            text_file.write( str(malicious_urls["usom-data"]["url-list"]["url-info"][counter_url]) + "\n")
        counter_url = counter_url + 1

def get_usom_malicious_urls():
    ''' request to USOM for get file which contains malicious urls '''
    usom_url = 'https://www.usom.gov.tr/url-list.xml'
    ''' after the request the program continues even if it receives an error. '''
    try:
        response = requests.get(usom_url,verify=False)
    except:
        print("Problem occured. No response was received.")
        return False
    if response.status_code == 200:
        return xmltodict.parse(response.content)
    else:
        print(F"Couldn't get content. Status Code: %"%(response.status_code))
        return False

''' main program '''
malicious_urls = get_usom_malicious_urls()
if malicious_urls != False:
    write_all_urls_to_json_file(malicious_urls)
    write_daily_urls_to_txt_file(malicious_urls)
else:
    print("Program Stopped.")
